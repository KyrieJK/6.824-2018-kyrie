# 分布式系统基础理论(八)	Lease机制(租约)

Lease机制是最重要的分布式协议，广泛应用于各种实际的分布式系统中。


   * [分布式系统基础理论(八)	Lease机制(租约)](#分布式系统基础理论八lease机制租约)
      * [基于lease的分布式cache系统](#基于lease的分布式cache系统)
      * [lease机制的分析](#lease机制的分析)
      * [基于lease机制确定节点状态](#基于lease机制确定节点状态)


## 基于lease的分布式cache系统

我们通常讨论一种分布式cache系统来介绍lease机制。Lease机制最初也是被运用于这种系统。

基本的问题背景如下：

在一个分布式系统中，有一个中心服务器节点，中心服务器存储、维护一些数据，这些数据是系统的元数据。系统中其他的节点通过访问中心服务器读取、修改当中的元数据。由于系统中各种操作都依赖于元数据，如果每次读取元数据的操作都访问中心服务器节点，那么中心服务器节点将会成为整个分布式系统的瓶颈。为此，设计一种元数据cache，在各个节点上cache元数据信息，从而减少对中心服务器节点的访问，提高性能。当然，系统的正确运行严格依赖于元数据的正确性，这就要求各个节点上cache的数据始终与中心服务器上的一致，cache中的数据不能是旧的脏数据。最后，设计的cache系统要能最大可能的处理节点宕机、网络中断等异常，最大程度的提高系统的可用性。

因此，基于lease机制设计一套cache系统，基本原理如下：

中心服务器在向各个节点发送数据时同时向节点颁发一个lease。每个lease具有一个有效期，和信用卡上的有效期类似，lease上的有效期通常是一个明确的时间点，一旦系统真实时间超过这个时间点，则lease过期失效。这样lease的有效期与节点收到lease的时间无关，节点可能收到lease时该lease就已经过期失效。我们需要假设整个分布式系统中的各个节点的时钟是同步的。中心服务器发出的lease的含义为：在lease有效期内，中心服务器保证不会修改对应元数据的值。因此，节点收到数据和lease后，将数据加入到本地cache中，一旦对应的lease超时，节点将对应的本地cache数据删除。中心服务器在修改数据时，首先阻塞所有新的读请求，并等待之前为该数据发出的所有lease超时过期，然后修改数据的值。

具体的一个服务器节点与客户端节点交互的基本流程如下：

基于lease的cache，客户端节点读取元数据

1. 判断元数据是否已经处于本地cache且lease处于有效期内

   true：直接返回cache中的元数据

   false：向中心服务器节点请求读取元数据信息

   ​		   服务器收到读取请求后，返回元数据及一个对应的lease

   ​		   客户端是否成功收到服务器返回的数据

   ​				失败或超时：退出流程，读取失败，可重试

   ​				成功：将元数据与该元数据的lease记录到内存中，返回元数据

基于lease的cache，客户端节点修改元数据流程

1. 节点向服务器发起修改元数据请求
2. 服务器收到修改请求后，阻塞所有新的读数据请求，即接收读请求，但不返回数据。
3. 服务器等待所有与该元数据相关的lease超时。
4. 服务器修改元数据并向客户端节点返回修改成功。

上述机制可以保证各个节点上的cache与中心服务器上的元数据始终一致。这是因为中心服务器节点在发送数据的同时会给对应节点颁发对应的lease，在lease有效期内，服务器不会修改数据，从而客户端节点可以放心的在lease有效期内cache数据。上述lease机制可以容错的关键是：服务器一旦发出数据及lease，无论客户端是否收到，也无论后续客户端是否宕机或者网络异常，服务器只需要等待lease超时，就可以保证对应的客户端节点不会再继续cache数据，从而可以放心地修改元数据而不用担心破坏cache的一致性。

上述基础流程有一些性能和可用性上的问题，但是经过一些改进是可以优化的。

1. 服务器修改元数据时需要阻塞所有新的读数据请求，造成读服务处于不可用状态。这是为了防止新的lease从而引起不断有新客户端持有lease并cache数据，形成”活锁“。优化的方法：服务器在进入修改元数据流程后，一旦收到读请求则只返回数据但不颁发lease。但是这样，会造成当服务器处于修改元数据流程中时，客户端可以读取元数据但是无法对元数据cache。当然我们可以进一步优化，当服务器进入修改流程，服务器颁发的lease有效期限选择为已发出的lease的最大有效期限。这样，即使客户端进入元数据修改流程，客户端仍然可以继续缓存元数据，但服务器的等待所有lease失效的时间也不会因为颁发新的lease而不断延长，造成”活锁“。
2. 优化点二是服务器在修改元数据时需要等待所有的lease过期超时，从而造成修改元数据的操作时延大大增加。优化的方法：在等待所有颁发的lease过期的过程中，服务器主动通知各个持有lease的客户端节点主动放弃lease并清除cache中的数据，如果服务器收到客户端返回的确认放弃lease的消息，则服务器不需要在等待该lease超时。该过程中，如果因为异常造成服务器通知失败或客户端节点发送确认消息失败，服务器只需依照原本的流程等待lease超时即可，不会对协议的正确性造成影响。

我们分析一下cache机制与多副本机制的区别。cache机制与多副本机制的相似之处都是将一份数据保存在多个节点上。对于cache的数据，可以随时删除丢弃，并命中cache的后果仅仅是需要访问数据源读取数据；但是多副本机制有所不同，副本是不能随意丢弃的，每丢弃一个副本，服务可用性都在下降，当副本数下降到一定程度，服务将会变得不可用。

## lease机制的分析

Lease是由颁发者授予的在某一有效期内的承诺。颁发者一旦发出lease，无论接收方是否收到，无论后续接收方处于何种状态，只要lease不过期，颁发者一定遵守承诺。对于接收方而言，接收方在lease有效期内可以使用颁发者授予的承诺，一旦lease过期，接收方则无法继续使用颁发者授予的承诺。

lease的这种承诺比较宽泛，不限定于具体内容，可以是数据的一致性，也可以是权限。如当需要做并发控制时，同一时刻只给某一节点颁发lease，只有持有lease的节点才可以修改数据；也可以是某种特殊身份，比如primary-secondary协议中，给某个节点颁发lease，只有持有lease的节点才具有primary身份。

lease机制具有很高的容错能力。Lease机制中”有效期“的概念，可以很好的应对网络异常情况的出现。Lease颁发过程只依赖于网络可以单向通信，即使接收方无法向颁发者发送具体消息，也不影响lease的颁发。由于lease的有效期是一个确定的时间点，lease中的有效期定义与发送lease的具体时间无关，所以同一个lease可以被颁发者不断重复向接收方发送，直至接收方返回确认收到的消息。即使颁发者偶尔发送lease失败，也可以通过重发的颁发解决。由此看来，Lease机制是一种幂等函数。一旦lease被接收方成功接收，后续lease机制不再依赖于网络通信，即使网络完全中断，lease机制也不受影响。

lease也具备很好的节点容错能力。即使颁发者节点宕机，但是丝毫不影响之前颁发出去的lease信息，不会影响lease的正确性。在颁发者节点恢复后，如果颁发者恢复了之前的lease信息，颁发者可以继续遵守lease的承诺。如果颁发者无法恢复lease信息，那么只需要等待一个最大的lease超时时间就可以使得所有的lease失效，从而不破坏lease机制。例如上节提到的cache系统，一旦服务器宕机，那么肯定无法修改元数据。待服务器重新恢复工作后，只要等待一个最大的lease超时时间，所有客户端节点上缓存的元数据信息都将被删除。对于接收方宕机的情况，颁发者不需要做更多的处理，只需要等待lease失效，就可以收回承诺。lease机制也不是必须依赖于存储。颁发者可以持久化颁发过的lease信息，从而在宕机恢复后可以使得在有效期的lease继续有效。但对于lease机制而言只是一个优化点，不是必须的。即使颁发者没有持久化lease信息，也可以通过等待一个最大的lease时间的方式使得之前所有颁发的lease失效，从而保证lease机制不被破坏。

我们可以看到，Lease机制强依赖于有效期，这就对于各个节点之间的时钟有严格要求。如果颁发者时钟比接收者的慢，那么当接收者认为lease已经过期的时候，颁发者依旧认为lease有效。接收者可以用在lease到期前申请新的lease解决这个问题。如果颁发者的时钟比接收者的快，当颁发者认为lease已经过期的时候，接收者依旧认为lease有效，颁发者可能将lease颁发给其他节点，造成lease机制失效。对于时钟不同步的情况，工程实践中通常的做法是将颁发者的有效期设置得比接收者的略大，需要大过时钟误差就可以避免对lease的有效性的影响。

## 基于lease机制确定节点状态

在分布式系统中确定一个节点是否处于正常工作状态是一个困难的问题。由于可能存在网络分化，节点的状态是无法通过网络通信来确定。

举个具体的例子：在一个primary-secondary架构的系统中，有三个节点A、B、C互为副本，其中有一个节点为primary，且同一时刻只能有一个primary节点。另有一个节点Q负责判断节点A、B、C的状态，一旦Q发现primary异常，节点Q将选择另一个节点作为primary。假设最开始节点A为primary，B、C为secondary。节点Q需要判断节点A、B、C的状态是否正常。

首先我们需要注意，基于”heartbeat“无法完善地解决这个问题。节点A、B、C可以周期性的向Q发送心跳信息，如果节点Q超过一段时间收不到某个节点的心跳，那么就会认为这个节点异常。这种方法的问题是假如节点Q收不到A上报的heartbeat，除了节点A本身的异常外，也有可能是Q与A之间的网络中断导致的。在工程实践中，更大的可能性不是网络中断，而是Q与A之间的网络拥塞造成的所谓的”瞬断“，这种”瞬断“往往可以很快恢复。另一种情况是节点Q的机器异常，导致A上报的heartbeat延迟处理了，以至于节点Q认为节点A没有发送heartbeat。假设节点A本身正常工作，但Q与节点A之间的网络瞬断，节点A与B、C之间的网络正常。此时节点Q认为节点A异常，重新选择节点B作为新的primary，并通知节点A、B、C新的primary是节点B。但是Q发出的这个通知消息到达各个节点的顺序无法确定，如果消息先到达B，则在这一时刻，系统中同时存在两个primary，分别是A、B。假如此时A、B都接收外部请求并与C同步数据，就可能产生严重的数据不一致现象。这就是分布式系统中常见的”脑裂split-brain“问题，或者也叫做”双主“问题。

这种问题的出现的原因在于节点Q认为节点A异常，但是节点A并不认为自己异常了，依然作为primary节点正常工作。问题的根源在于由于网络分化造成的系统对于”节点状态“认知的不一致。

primary-secondary协议依赖于对节点状态认知的全局一致性，即一旦节点Q认为某个节点A异常，则节点A也必须认为自己异常(即使机器本身没有问题)，从而节点A停止作为primary，避免”双主“问题出现。解决这种全局一致性认知问题有两种思路：

1. 设计的分布式协议可以容忍”双主“问题，不依赖对节点状态的全局一致性认知；或者全局一致性状态是全体协商后的结果，不由单个节点(比如Q)判定，本质上来说就是放弃中心化的设计，改用去中心化设计。
2. 利用lease机制判定节点状态。

由中心节点向其他节点发送lease，若某个节点持有有效的lease，则认为该节点正常可以提供服务。节点A、B、C周期性地发送heartbeat上报给Q自身状态，节点Q收到heartbeat后发送一个lease，表示节点Q确认了节点A、B、C的状态，并允许节点在lease有效期内正常工作。节点Q可以给primary节点一个特殊的lease，表示节点可以作为primary。一旦节点Q希望切换新的primary，则只需要等待前一个primary的lease过期，再重新颁发新的lease给新的节点，而不会出现”双主“问题。

但是还需要注意的是，在实际工程中，只用一个中心节点判定节点状态，发送lease是存在SPOF问题的。一旦中心节点宕机或发生网络异常，则所有的节点没有lease，从而造成系统不可用。因此，在工程实践中，总是使用多个中心节点组成一个集群，互为副本，该集群具有高可用性，对外提供颁发lease的功能。chubby和zookeeper都是基于这样的设计。

